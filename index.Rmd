---
title: "Predicting the Quality of Exercise Using Wearable Fitness Devices"
author: "Brandon Maus"
date: "July 8, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(ggplot2)
library(caret)
library(randomForest)
```

```{r loadData, include=FALSE, cache=TRUE}
trainFull <- read_csv("pml-training.csv")
testProbe <- read_csv("pml-testing.csv")

set.seed(42)
inTrain <- createDataPartition(y = trainFull$classe, p = 0.75, list = FALSE)
inValidate <- createDataPartition(y = trainFull[-inTrain, ]$classe, p = 0.5, list = FALSE)
train    <- trainFull[inTrain, ]
validate <- trainFull[-inTrain, ][inValidate, ]
test     <- trainFull[-inTrain, ][-inValidate, ]
```


```{r featureSelect, include=FALSE, cache=TRUE}
# badVars contains near zero variance variables, the row index, user name,
# timestamp columns, and the time window columns.
badVars <- c(nearZeroVar(train), 1:5, 7)
filteredTrain <- train[, -badVars]
goodVars <- colSums(is.na(filteredTrain)) == 0

filteredTrain     <- filteredTrain[, goodVars]
filteredValidate  <-  validate[, -badVars][, goodVars]
filteredTest      <-      test[, -badVars][, goodVars]
filteredTestProbe <- testProbe[, -badVars][, goodVars]
```

```{r lda, include=FALSE, eval=FALSE}
set.seed(71)
fitLDA <- train(classe ~ ., method = "lda", data = filteredTrain)
fitLDAWithPCA <- train(classe ~ ., method = "lda", data = filteredTrain,
                       preProcess = c("pca"), 
                       trControl = trainControl(preProcOptions = list(thresh = 0.95)))

fitQDA <- train(classe ~ ., method = "qda", data = filteredTrain)
fitQDAWithPCA <- train(classe ~ ., method = "qda", data = filteredTrain,
                       preProcess = c("pca"), 
                       trControl = trainControl(preProcOptions = list(thresh = 0.95)))
```

```{r gbm, include=FALSE, eval=FALSE}
set.seed(73)
fitGBM <- train(classe ~ ., method = "gbm", data = filteredTrain, verbose = FALSE)
```

```{r randomForestFit, include=FALSE, eval=FALSE}
set.seed(79)
fitRF <- train(classe ~ ., method = "rf", data = filteredTrain)
```

# Overview

Wearable fitness monitors provide a trove of information ready for analysis. One such dataset is hosted by the Groupware research group (http://groupware.les.inf.puc-rio.br/har). It contains measures on the movements of participants' upper arm, lower arm, belt, and from a weight during an exercise routine. These measures are paired with an indicator variable signifying how well the participant was performing the exercise. Our goal here is to develop a classifier using the output of the wearable fitness devices in order to predict the quality of the exercise. Random forests were found to perform best of the tried models with an out of sample error of 0.0078 (accuracy of 99.22%) as measured on a hold out test data set.

The R code for this analysis can be found in the appendix.

## Feature Selection

Features were selected for inclusion into the models through a combination of analytical methods and softer judgement calls. To begin, variables detected as having near zero variance via caret's `nearZeroVar` function were dropped. This left the user name and sample index columns, which would not generalize well. The current project is the development a general predictor for exercise quality, not a user personalized one. As time series style models were only very briefly touched upon in this course, I decided not to pursue time series models. This led me to drop the timestamp and window columns. Finally, columns with any missing values were excluded. The result of these filters were 49 complete predictors.

## Exploration

Before moving into developing models, some brief data exploration was performed. The following plot is an example of that exploration. The general takeaway is that there are indeed patterns in the data that can be used to predict the quality of the exercise performance. A good classifier using these patterns is likely to be both non-linear and multi-dimensional in nature.

```{r explorePlot}
ggplot(aes(x = roll_forearm, y = yaw_forearm, color = classe), data = filteredTrain) + 
    geom_point(alpha = 0.3) +
    labs(title = "Roll vs yaw of the forearm colored by classe")
```

## Modeling

The available training data was first split into a 75% training data set, 12.5% validation set, and 12.5% test set. All algorithms were built on the training data and evaluated with the validation set. The test set was held for the algorithm performing best on the validation set. Linear discriminant analysis (LDA), quadratic discriminant analysis (QDA), stochastic gradient boosting (GBM), and random forests (RF) were the candidate machine learing algorithms The following table holds performance metrics for each of these algorithms.

| Algorithm  | Preproccessing | Estimated OOS<br/>Accuracy | Train<br/>Accuracy | Validation<br/>Accuracy | Test<br/>Accuracy |
|------------|----------------|:--------------------------:|:------------------:|:-----------------------:|:-----------------:|
| LDA        | --             | 0.6436                     | 0.6484             | 0.6390                  | --                |
| LDA        | PCA            | 0.5130                     | 0.5099             | 0.5212                  | --                |
| QDA        | --             | 0.8717                     | 0.8777             | 0.8745                  | --                |
| QDA        | PCA            | 0.7279                     | 0.7210             | 0.7176                  | --                |
| GBM        | --             | 0.9500                     | 0.9686             | 0.9560                  | --                |
| RF         | --             | 0.9880                     | 1.0000             | 0.9951                  | 0.9922            |

Each of the above models were performed using the caret package's default resampling method to tune the model and acquire an estimate of out of sample (OOS) error. This default setting builds 25 bootstrap data sets by sampling with replacement from the training data. The model building is tuned using these bootstrap training sets and then a final model is built from the best parameters. The caret `confusionMatrix` function was  used with the resulting trained models to evaluate their accuracy on the training, validation, and test sets.

Modeling attempts began with LDA, a linear classifier. LDA attempts to draw straight lines through the feature space that separates the various outcome categories. This model was found to perform relatively poorly. One explanation for the poor fit is that individual features do not sufficiently separate the cases but that combinations of features might do better. If this is true, then the LDA model might be improved by preprocessing with principle component analysis. PCA would hopefully pick up on the combinations of directions that describe the classes, making LDA's job easier. LDA was thus run again with PCA as a preprocessing step set to retain 95% of the variance in the training data. This model was found to perform worse than LDA without the preprocessing. Quadratic discriminant analysis (QDA) was also tried, again with and without PCA. Though the quadratic form was better than the linear, these models were still relatively weak.

The stochastic gradient boosting (GBM) and random forest (RF) learning algorithm were tried next. Their results were much more encouraging. This is not surprising given the exploration described above. Successful models for this domain would need the ability to divide the feature space in more complex ways than straight lines or quadratic curves allow. Random forests were the best performing model on the validation set. It was thus the sole model evaluated on the test set, achieving an 95% confidence interval of (0.9879, 0.9953) accuracy there.

## Appendix

### Data Loading and Feature Selection
```{r ref.label="loadData", eval=FALSE, echo = TRUE}
```
```{r ref.label="featureSelect", eval=FALSE, echo = TRUE}
```

### Linear and Quadratic Discriminant Analysis
```{r ref.label="lda", eval=FALSE, echo = TRUE}
```

### Stochastic Gradient Boosting
```{r ref.label="gbm", eval=FALSE, echo = TRUE}
```

### Random Forests
```{r ref.label="randomForestFit", eval=FALSE, echo = TRUE}
```